{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 8: Simulating bias for testing mitigation models and fairness\n",
    "\n",
    "The project aims to simulate bias in data and evaluate how machine learning models trained on biased data behave. Additionally, it will assess different methods to mitigate bias and improve the fairness of the model’s predictions. The main focus is to understand the impact of biased data on a machine learning system and how fairness interventions affect outcomes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias In Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias in Data and its Simulation\n",
    "\n",
    "In machine learning (ML), bias refers to systematic errors in data that can lead to unfair decisions. Simulating bias involves generating synthetic datasets that replicate these errors, allowing researchers to analyze the impact of bias on model performance and fairness. Through these simulations, researchers can develop methods to mitigate bias, ensuring fairness and accuracy in decision-making processes.\n",
    "\n",
    "Bias can appear at various stages of the ML pipeline, from data collection to model deployment. If left unchecked, these biases can perpetuate societal inequalities. Simulating bias helps explore its consequences in controlled scenarios, providing insights into how different types of bias affect both fairness and model accuracy.\n",
    "\n",
    "### Four Fundamental Types of Bias\n",
    "1. **Historical Bias**: This type of bias occurs when societal inequalities are reflected in the data. For example, differences in income between genders can reflect past injustices, embedding unfair patterns in the data.\n",
    "2. **Measurement Bias**: Arises when a proxy variable, instead of the true value, is used in decision-making. For example, using IQ tests as a proxy for intelligence may introduce bias if the tests favor certain groups.\n",
    "3. **Representation Bias**: Happens when a specific subgroup (e.g., based on ethnicity or gender) is underrepresented or misrepresented in the data, leading to biased outcomes.\n",
    "4. **Omitted Variable Bias**: Occurs when an important variable is omitted, resulting in a model that depends on other variables, potentially correlating with sensitive attributes.\n",
    "\n",
    "### Mathematical Explanation of Bias\n",
    "\n",
    "We model the relationships between variables and simulate bias using the following equations:\n",
    "\n",
    "- Let X represent the feature set, and Y be the target variable. The relationship between these variables can be expressed as: Y = f(X) + ε\n",
    "  where f(X) is the function describing the relationship between features and the target, and ε represents noise.\n",
    "\n",
    "Different types of bias affect this system in various ways:\n",
    "\n",
    "- **Historical Bias**: Occurs when a sensitive attribute A impacts both the features X and the target Y. For example: X = g(X) - βh A where βh is the parameter that determines the strength of historical bias.\n",
    "\n",
    "- **Measurement Bias**: When proxies \\( Px \\) and \\( Py \\) are observed instead of true values X and Y, and these proxies are affected by sensitive attributes:\n",
    "  \\[\n",
    "  Px = X - βm A + N_Px\n",
    "  \\]\n",
    "  Here, βm is the measurement bias parameter, and N_Px represents random noise affecting the proxy variable.\n",
    "\n",
    "- **Representation Bias**: This bias can be modeled by undersampling a subgroup of individuals with a sensitive attribute A = 1. The proportion of the undersampled group can be represented as Pu, the undersampling parameter.\n",
    "\n",
    "- **Omitted Variable Bias**: This occurs when an important feature is missing. For instance, omitting R from the model and using only X could result in spurious dependencies on the sensitive attribute A.\n",
    "\n",
    "By adjusting the parameters βh, βm, and Pu, we can simulate various types of bias and examine their effects on fairness and model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synth(var_config):\n",
    "\n",
    "    dim=1000 # Dimension of the dataset\n",
    "\n",
    "    l_y=4 # Lambda coefficient for historical bias on the target y\n",
    "    l_h_r=1.5 # Lambda coefficient for historical bias on R\n",
    "    l_h_q=1 # Lambda coefficient for historical bias on Q\n",
    "\n",
    "    thr_supp=1 # Threshold correlation for discarding features too much correlated with s\n",
    "\n",
    "    l_m=1 # Lambda coefficient for measurement bias. If l_m!=0 P substitutes R.\n",
    "    l_m_y=0 # Lambda coefficient for measurement bias on the target y\n",
    "\n",
    "    Pu=1 # Percentage of undersampling instance with A=1\n",
    "    \n",
    "    l_r=False # Boolean for inducing representation bias, that is undersampling conditioning on a variable, e.g. R\n",
    "    l_o=False # Boolean variable for excluding an important variable, e.g. X2\n",
    "\n",
    "    l_y_b=0 # Lambda coefficient for interaction proxy bias, i.e., historical bias on the label y with lower values of y for individuals in group A=1 with high values for the feature R\n",
    "\n",
    "    l_q=2 # Lambda coefficient for importance of Q for Y\n",
    "    sy=1 # Standard deviation of the noise of Y\n",
    "    l_r_q=0 # Lambda coefficient that quantifies the influence from R to Q\n",
    "\n",
    "    l_m_y_non_linear = True # Boolean variable for inducing non-linear measurement bias on the target y. The magnitude of the measurement bias is defined by the parameter `l_m_y`.\n",
    "    y_binary = False # Changes the output to binary if True, continuous if False; In binary, Y is 1 if above mean, 0 otherwise\n",
    "\n",
    "    # Values to generate Y (Output Variable)\n",
    "    real_y_mean = 10000\n",
    "    real_y_std = 5000\n",
    "    N1 = np.random.normal(real_y_mean, real_y_std, dim)\n",
    "    N2 = np.random.normal(1, 0.5, dim)\n",
    "\n",
    "\n",
    "    # Create variable A (can be multiple)\n",
    "    A_vars = {}\n",
    "    for var in var_config.get('A', []):\n",
    "        A_vars[var['name']] = np.random.binomial(1, 0.5, size=dim)\n",
    "\n",
    "\n",
    "    # Initialize R based on N1 and historical bias from A\n",
    "    R = N1.copy()\n",
    "    for var in var_config.get('A', []):\n",
    "        A_var = A_vars[var['name']]\n",
    "        R -= var['coef'] * A_var\n",
    "\n",
    "    # Create R_A, influenced by R and historical bias from A\n",
    "    R_A = 1 / (1 + np.exp(l_r_q * R))\n",
    "\n",
    "    Np = np.random.normal(0, 2, dim)\n",
    "    Ny = np.random.normal(0, sy, dim)\n",
    "\n",
    "    # Create variable Q (can be multiple)\n",
    "    Q_vars = {}\n",
    "    for var in var_config.get('Q', []):\n",
    "        Q_vars[var['name']] = np.random.binomial(3, R_A)\n",
    "\n",
    "    # Y variable with measurement and historical bias\n",
    "    y = R.copy()\n",
    "    for var in var_config.get('A', []):\n",
    "        A_var = A_vars[var['name']]\n",
    "        y -= l_y * A_var + l_m_y * A_var * (R < np.median(R)) - l_m_y * A_var * (R >= np.median(R))\n",
    "\n",
    "    for var in var_config.get('Q', []):\n",
    "        Q_var = Q_vars[var['name']]\n",
    "        y -= var['coef'] * Q_var\n",
    "        \n",
    "    y += Ny  # Add noise to y\n",
    "\n",
    "    # y_real (without measurement bias)\n",
    "    y_real = R.copy()\n",
    "    for var in var_config.get('A', []):\n",
    "        A_var = A_vars[var['name']]\n",
    "        y_real -= l_y * A_var\n",
    "\n",
    "    for var in var_config.get('Q', []):\n",
    "        Q_var = Q_vars[var['name']]\n",
    "        y_real -= var['coef'] * Q_var\n",
    "\n",
    "    y_real += Ny\n",
    "\n",
    "\n",
    "\n",
    "    # Create proxy variables for P (if l_m != 0)\n",
    "    P_vars = {}\n",
    "    if l_m != 0:\n",
    "        for var in var_config.get('P', []):\n",
    "            P_vars[var['name']] = R - var['coef'] * A_vars[list(A_vars.keys())[0]] + Np\n",
    "            print(f\"Correlation between R and {var['name']}: \", np.corrcoef(P_vars[var['name']], R))\n",
    "\n",
    "    # Assemble the dataset\n",
    "    data = {'R': R, 'Y': y, 'Y_real': y_real}\n",
    "    data.update(A_vars)\n",
    "    data.update(Q_vars)\n",
    "    if P_vars:\n",
    "        data.update(P_vars)\n",
    "\n",
    "    dtf = pd.DataFrame(data)\n",
    "\n",
    "    # Undersample instances where A == 1\n",
    "    int_Pu = int(((dtf[list(A_vars.keys())[0]] == 1).sum()) * Pu)\n",
    "    if int_Pu > 0:\n",
    "        if l_r:\n",
    "            drop_index = dtf.loc[dtf[list(A_vars.keys())[0]] == 1, :].sort_values(by='R', ascending=True).index\n",
    "            dtf = dtf.drop(drop_index[int_Pu:])\n",
    "        else:\n",
    "            dtf = dtf.drop(dtf.index[dtf[list(A_vars.keys())[0]] == 1][int_Pu:])\n",
    "\n",
    "    # Optionally delete an important variable for omission (l_o)\n",
    "    if l_o:\n",
    "        for var in ['R'] + list(P_vars.keys()):\n",
    "            if var in dtf.columns:\n",
    "                del dtf[var]\n",
    "\n",
    "\n",
    "    # Define feature matrix X and target Y\n",
    "    X = dtf.reset_index(drop=True)\n",
    "    y = X['Y']\n",
    "    y_real = X['Y_real']\n",
    "    del X['Y']\n",
    "    del X['Y_real']\n",
    "\n",
    "    # Define threshold making y binary\n",
    "    if y_binary:\n",
    "        thres = y.mean()\n",
    "        y = pd.Series(1*(y > thres))\n",
    "        y_real = pd.Series(1*(y_real > thres))\n",
    "\n",
    "    # Split train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.33, random_state=42, stratify=X[list(A_vars.keys())[0]] == 1\n",
    "    )\n",
    "\n",
    "    # Create individual and suppression sets\n",
    "    X_ind_train = X_train[[i for i in X_train.columns if i not in list(A_vars.keys())]]\n",
    "    X_ind_test = X_test[[i for i in X_test.columns if i not in list(A_vars.keys())]]\n",
    "\n",
    "    X_supp_train = X_train[[i for i in X_train.columns if i not in list(A_vars.keys()) and\n",
    "                            abs(np.corrcoef(X_train[i], X_train[list(A_vars.keys())[0]])[0, 1]) < thr_supp]]\n",
    "    X_supp_test = X_test[[i for i in X_test.columns if i not in list(A_vars.keys()) and\n",
    "                          abs(np.corrcoef(X_train[i], X_train[list(A_vars.keys())[0]])[0, 1]) < thr_supp]]\n",
    "\n",
    "    # Return the generated dataset and variables\n",
    "    y_train_real = y_real[y_train.index]\n",
    "    y_test_real = y_real[y_test.index]\n",
    "\n",
    "    return X_train, X_ind_train, X_supp_train, X_test, X_ind_test, X_supp_test, y_train, y_test, y_train_real, y_test_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between R and P1:  [[1.         0.99517256]\n",
      " [0.99517256 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "vars = {\n",
    "    'A': [\n",
    "        {'name': 'A1', 'coef': 1000},\n",
    "        {'name': 'A2', 'coef': 50},\n",
    "    ],\n",
    "    'Q': [\n",
    "        {'name': 'Q1', 'coef': 1000},\n",
    "    ],\n",
    "    'P': [\n",
    "        {'name': 'P1', 'coef': 1000},\n",
    "    ],\n",
    "}\n",
    "\n",
    "X_train, X_ind_train, X_supp_train, X_test, X_ind_test, X_supp_test, y_train, y_test, y_train_real, y_test_real = create_synth(vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('data/X_train.csv', index=False)\n",
    "X_ind_train.to_csv('data/X_ind_train.csv', index=False)\n",
    "X_supp_train.to_csv('data/X_supp_train.csv', index=False)\n",
    "X_test.to_csv('data/X_test.csv', index=False)\n",
    "X_ind_test.to_csv('data/X_ind_test.csv', index=False)\n",
    "X_supp_test.to_csv('data/X_supp_test.csv', index=False)\n",
    "y_train.to_csv('data/y_train.csv', index=False)\n",
    "y_test.to_csv('data/y_test.csv', index=False)\n",
    "y_train_real.to_csv('data/y_train_real.csv', index=False)\n",
    "y_test_real.to_csv('data/y_test_real.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Mitigation and Fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "**Baumann, Joachim**, **Castelnovo, Alessandro**, **Crupi, Riccardo**, **Inverardi, Nicole**, and **Regoli, Daniele**. 2023. **Bias on Demand: A Modelling Framework That Generates Synthetic Data With Bias**. *In Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency*. [https://doi.org/10.1145/3593013.3594058](https://doi.org/10.1145/3593013.3594058).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
